# Ollama API Configuration
OLLAMA_URL=http://localhost:11434/api/embed
AUTH_TOKEN=  # Optional: only include if your Ollama setup requires authentication
EMBEDDING_MODEL=embeddinggemma:latest  # or qwen3-embedding:0.6b (for large docs), nomic-embed-text, mxbai-embed-large

# Qdrant Configuration
QDRANT_URL=http://localhost:6333  # Use localhost if running with docker-compose
COLLECTION_NAME=documents

# Web UI Server Configuration (optional)
SERVER_PORT=3001  # Port for Express API server
MAX_FILE_SIZE_MB=10  # Maximum file upload size in MB (default: 10)

# Visualization Cache Strategy
VIZ_CACHE_STRATEGY=memory  # 'memory' (default, in-RAM) or 'redis' (external Redis server)
VIZ_CACHE_TTL=3600000  # Cache TTL in milliseconds (default: 3600000 = 1 hour)
REDIS_URL=redis://localhost:6379  # Required only if VIZ_CACHE_STRATEGY=redis

# Automatic Categorization (optional)
CATEGORIZATION_MODEL=  # e.g., gemma3:4b (recommended), llama3.2:latest - leave empty to disable auto-categorization

# PII Detection Configuration (optional)
PII_DETECTION_ENABLED=false  # Set to 'true' to enable PII detection on uploaded documents
PII_DETECTION_METHOD=hybrid  # Options: 'ollama', 'regex', 'hybrid', 'compromise', 'advanced'
PII_DETECTION_MODEL=  # e.g., gemma3:4b (recommended), llama3.2:latest - defaults to EMBEDDING_MODEL if not specified
